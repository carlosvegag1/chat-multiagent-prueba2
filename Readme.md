# ðŸ“‹ DocumentaciÃ³n TÃ©cnica Completa

## Sistema de EvaluaciÃ³n de Candidatos con LangChain

> **VersiÃ³n**: 2.1.0  
> **Ãšltima actualizaciÃ³n**: Diciembre 2024  
> **Stack principal**: Python 3.9+ | LangChain | LangGraph | FAISS | Streamlit

---

## ðŸ“‘ Ãndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Arquitectura TÃ©cnica del Sistema](#2-arquitectura-tÃ©cnica-del-sistema)
3. [Stack TecnolÃ³gico](#3-stack-tecnolÃ³gico)
4. [Patrones de DiseÃ±o Implementados](#4-patrones-de-diseÃ±o-implementados)
5. [Diagramas TÃ©cnicos](#5-diagramas-tÃ©cnicos)
6. [LangChain como Pilar TecnolÃ³gico](#6-langchain-como-pilar-tecnolÃ³gico)
7. [Sistema RAG Conversacional](#7-sistema-rag-conversacional)
8. [Funcionalidades Premium Opcionales](#8-funcionalidades-premium-opcionales)
9. [Pipeline de Procesamiento](#9-pipeline-de-procesamiento)
10. [Arquitectura de CÃ³digo](#10-arquitectura-de-cÃ³digo)
11. [Sistema de Logging Operacional](#11-sistema-de-logging-operacional)
12. [GestiÃ³n de Configuraciones](#12-gestiÃ³n-de-configuraciones)
13. [Estrategias de Escalabilidad](#13-estrategias-de-escalabilidad)
14. [GuÃ­a de Despliegue](#14-guÃ­a-de-despliegue)
15. [MÃ©tricas y Observabilidad](#15-mÃ©tricas-y-observabilidad)

---

## 1. Resumen Ejecutivo

### 1.1 Â¿QuÃ© es este sistema?

El **Sistema de EvaluaciÃ³n de Candidatos** es una soluciÃ³n empresarial de Inteligencia Artificial que automatiza el proceso de evaluaciÃ³n de candidatos contra ofertas de empleo. Utiliza las capacidades mÃ¡s avanzadas de **LangChain** para garantizar evaluaciones precisas, trazables y escalables.

### 1.2 Propuesta de Valor

| Para Stakeholders | Beneficio |
|-------------------|-----------|
| **Reclutadores** | Reduce tiempo de evaluaciÃ³n de 6-7 minutos a 30-60 segundos por candidato |
| **Managers** | Criterios objetivos y consistentes eliminan sesgo humano |
| **Candidatos** | EvaluaciÃ³n justa basada en evidencia documentada |
| **IT/DevOps** | Arquitectura modular, escalable y observable |

### 1.3 Capacidades Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPACIDADES DEL SISTEMA                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ðŸŽ¯ CORE                        ðŸš€ PREMIUM (OPCIONAL)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  âœ“ ExtracciÃ³n de requisitos    âœ“ LangGraph Multi-Agente                â”‚
â”‚  âœ“ Matching CV-Requisitos      âœ“ Embeddings SemÃ¡nticos FAISS           â”‚
â”‚  âœ“ Entrevista interactiva      âœ“ RAG para Historial                    â”‚
â”‚  âœ“ Multi-proveedor LLM         âœ“ LangSmith Trazabilidad                â”‚
â”‚  âœ“ Niveles de confianza        âœ“ Streaming en tiempo real              â”‚
â”‚  âœ“ Persistencia de historial   âœ“ Logging operacional                   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Arquitectura TÃ©cnica del Sistema

### 2.1 VisiÃ³n General de Capas

El sistema implementa una **arquitectura por capas** que separa claramente las responsabilidades:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CAPA DE PRESENTACIÃ“N                             â”‚
â”‚                         (Streamlit UI)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Nueva         â”‚  â”‚   Historial     â”‚  â”‚   Opciones      â”‚         â”‚
â”‚  â”‚   EvaluaciÃ³n    â”‚  â”‚   + RAG Chat    â”‚  â”‚   Avanzadas     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         CAPA DE ORQUESTACIÃ“N                             â”‚
â”‚                         (CandidateEvaluator)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         FASE 1               â”‚  â”‚         FASE 2               â”‚  â”‚
â”‚  â”‚    Phase1Analyzer            â”‚  â”‚    Phase2Interviewer         â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚    â”‚ LangGraph (opcional)â”‚   â”‚  â”‚    â”‚ GeneraciÃ³n preguntasâ”‚   â”‚  â”‚
â”‚  â”‚    â”‚ Embeddings (opcional)â”‚   â”‚  â”‚    â”‚ EvaluaciÃ³n respuestaâ”‚   â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         CAPA DE SERVICIOS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LLMFactory  â”‚  â”‚ SemanticMatchâ”‚  â”‚  RAG/Vector  â”‚  â”‚  UserMemory â”‚ â”‚
â”‚  â”‚  (LLMs)      â”‚  â”‚  (FAISS)     â”‚  â”‚  (Historial) â”‚  â”‚  (Storage)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         CAPA DE INFRAESTRUCTURA                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   OpenAI     â”‚  â”‚   Google     â”‚  â”‚  Anthropic   â”‚  â”‚  LangSmith  â”‚ â”‚
â”‚  â”‚   API        â”‚  â”‚   Gemini     â”‚  â”‚   Claude     â”‚  â”‚  Tracing    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Componentes Principales

| Componente | UbicaciÃ³n | Responsabilidad |
|------------|-----------|-----------------|
| **CandidateEvaluator** | `core/evaluator.py` | Orquestador principal que coordina las fases |
| **Phase1Analyzer** | `core/analyzer.py` | ExtracciÃ³n de requisitos y matching con CV |
| **Phase2Interviewer** | `core/interviewer.py` | GeneraciÃ³n de preguntas y evaluaciÃ³n de respuestas |
| **SemanticMatcher** | `core/embeddings.py` | BÃºsqueda de evidencia semÃ¡ntica con FAISS |
| **LangGraph** | `core/graph.py` | OrquestaciÃ³n multi-agente |
| **LLMFactory** | `llm/factory.py` | Factory para creaciÃ³n de LLMs multi-proveedor |
| **HistoryChatbot** | `rag/chatbot.py` | Chatbot RAG para consultas de historial |
| **UserMemory** | `storage/memory.py` | Persistencia de evaluaciones |

---

## 3. Stack TecnolÃ³gico

### 3.1 TecnologÃ­as Core

```mermaid
mindmap
  root((Stack TecnolÃ³gico))
    LangChain Ecosystem
      langchain-core
      langchain-openai
      langchain-community
      langgraph
      langsmith
    AI/ML
      OpenAI GPT-4
      Google Gemini
      Anthropic Claude
      FAISS Embeddings
    Backend
      Python 3.9+
      Pydantic v2
      Structured Output
    Frontend
      Streamlit
      Real-time Streaming
    Storage
      JSON Files
      FAISS VectorStore
```

### 3.2 JustificaciÃ³n de Elecciones TecnolÃ³gicas

| TecnologÃ­a | JustificaciÃ³n | Alternativas Consideradas |
|------------|---------------|---------------------------|
| **LangChain** | Framework lÃ­der para aplicaciones LLM con abstracciÃ³n de proveedores | LlamaIndex, raw OpenAI SDK |
| **LangGraph** | OrquestaciÃ³n multi-agente nativa de LangChain, soporte de estados | CrewAI, AutoGen |
| **FAISS** | Alta performance para bÃºsqueda vectorial, sin servidor externo | Pinecone, Chroma, Weaviate |
| **Pydantic v2** | ValidaciÃ³n de datos robusta, integraciÃ³n nativa con Structured Output | dataclasses, attrs |
| **Streamlit** | Desarrollo rÃ¡pido de UI, integraciÃ³n Python nativa | Gradio, FastAPI+React |
| **LangSmith** | Trazabilidad end-to-end nativa de LangChain | Weights&Biases, MLflow |

### 3.3 Dependencias del Proyecto

```python
# Core LangChain
langchain>=0.1.0
langchain-openai>=0.0.2
langchain-community>=0.0.10
langchain-core>=0.1.23

# Multi-provider LLM
openai>=1.10.0
langchain-google-genai>=0.0.6
langchain-anthropic>=0.1.0

# OrquestaciÃ³n y Observabilidad
langgraph>=0.0.20
langsmith>=0.0.80

# Embeddings SemÃ¡nticos
faiss-cpu>=1.7.4

# Web Application
streamlit>=1.28.0
pydantic>=2.5.3
```

---

## 4. Patrones de DiseÃ±o Implementados

### 4.1 Factory Pattern (LLMFactory)

**PropÃ³sito**: Abstraer la creaciÃ³n de instancias de LLM de diferentes proveedores.

```python
# UbicaciÃ³n: src/evaluator/llm/factory.py

class LLMFactory:
    """Factory para crear instancias de LLM de diferentes proveedores"""
    
    @staticmethod
    def create_llm(
        provider: str,      # "openai", "google", "anthropic"
        model_name: str,    # "gpt-4", "gemini-pro", "claude-3"
        temperature: float,
        api_key: Optional[str] = None
    ) -> BaseChatModel:
        """
        Crea una instancia de LLM del proveedor especificado.
        El cliente no necesita conocer los detalles de cada proveedor.
        """
        if provider == "openai":
            return ChatOpenAI(model=model_name, temperature=temperature)
        elif provider == "google":
            return ChatGoogleGenerativeAI(model=model_name, temperature=temperature)
        elif provider == "anthropic":
            return ChatAnthropic(model=model_name, temperature=temperature)
```

**Beneficios**:
- Cambio de proveedor sin modificar cÃ³digo cliente
- CentralizaciÃ³n de lÃ³gica de creaciÃ³n
- FÃ¡cil extensiÃ³n para nuevos proveedores

### 4.2 Strategy Pattern (Modos de AnÃ¡lisis)

**PropÃ³sito**: Permitir diferentes estrategias de anÃ¡lisis (tradicional vs LangGraph).

```python
# UbicaciÃ³n: src/evaluator/core/analyzer.py

class Phase1Analyzer:
    def analyze(self, job_offer: str, cv: str) -> Phase1Result:
        # Strategy selection basada en configuraciÃ³n
        if self.use_langgraph and self._graph:
            return self._analyze_with_langgraph(job_offer, cv)  # Strategy A
        else:
            return self._analyze_traditional(job_offer, cv)      # Strategy B
```

**Diagrama de Strategy Pattern**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase1Analyzer                            â”‚
â”‚                                                              â”‚
â”‚   use_langgraph: bool                                        â”‚
â”‚   use_semantic_matching: bool                                â”‚
â”‚                                                              â”‚
â”‚   analyze(job_offer, cv) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                 â”‚
                    â–¼                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   LangGraph Strategy  â”‚       â”‚  Traditional Strategy â”‚
        â”‚                       â”‚       â”‚                       â”‚
        â”‚  - Multi-agente       â”‚       â”‚  - Secuencial         â”‚
        â”‚  - 4 nodos            â”‚       â”‚  - Directo            â”‚
        â”‚  - Estado compartido  â”‚       â”‚  - MÃ¡s simple         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Singleton Pattern (OperationalLogger)

**PropÃ³sito**: Garantizar una Ãºnica instancia del logger en toda la aplicaciÃ³n.

```python
# UbicaciÃ³n: src/evaluator/core/logging_config.py

class OperationalLogger:
    _instance: Optional['OperationalLogger'] = None
    
    def __new__(cls) -> 'OperationalLogger':
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
```

### 4.4 Repository Pattern (UserMemory)

**PropÃ³sito**: Abstraer el acceso a datos de evaluaciones.

```python
# UbicaciÃ³n: src/evaluator/storage/memory.py

class UserMemory:
    """Gestor de memoria por usuario - Abstrae persistencia"""
    
    def save_evaluation(self, user_id, ...) -> UserEvaluation
    def get_user_evaluations(self, user_id) -> List[Dict]
    def get_enriched_evaluations(self, user_id) -> List[Dict]
    def save_enriched_evaluation(self, enriched) -> EnrichedEvaluation
```

### 4.5 Resumen de Patrones

| PatrÃ³n | UbicaciÃ³n | Beneficio |
|--------|-----------|-----------|
| **Factory** | `LLMFactory` | AbstracciÃ³n de creaciÃ³n de LLMs |
| **Strategy** | `Phase1Analyzer` | Intercambio de algoritmos de anÃ¡lisis |
| **Singleton** | `OperationalLogger` | Ãšnica instancia de logging |
| **Repository** | `UserMemory` | AbstracciÃ³n de persistencia |
| **Builder** | `EnrichedEvaluation` | ConstrucciÃ³n compleja de objetos |
| **Observer** | Streaming callbacks | NotificaciÃ³n de progreso |

---

## 5. Diagramas TÃ©cnicos

### 5.1 Diagrama de Arquitectura General

```mermaid
graph TB
    subgraph "Capa de PresentaciÃ³n"
        UI[Streamlit UI]
    end
    
    subgraph "Capa de AplicaciÃ³n"
        CE[CandidateEvaluator]
        P1[Phase1Analyzer]
        P2[Phase2Interviewer]
    end
    
    subgraph "Capa de Dominio"
        SM[SemanticMatcher]
        LG[LangGraph]
        RC[RAG Chatbot]
    end
    
    subgraph "Capa de Infraestructura"
        LLM[LLMFactory]
        VS[VectorStore]
        UM[UserMemory]
    end
    
    subgraph "Proveedores Externos"
        OAI[OpenAI API]
        GCP[Google Gemini]
        ANT[Anthropic Claude]
        LS[LangSmith]
    end
    
    UI --> CE
    CE --> P1
    CE --> P2
    P1 --> SM
    P1 --> LG
    UI --> RC
    
    P1 --> LLM
    P2 --> LLM
    SM --> VS
    RC --> VS
    RC --> UM
    
    LLM --> OAI
    LLM --> GCP
    LLM --> ANT
    LLM --> LS
```

### 5.2 Flujo de EvaluaciÃ³n de Ofertas (Paso a Paso)

```mermaid
sequenceDiagram
    participant U as Usuario
    participant UI as Streamlit
    participant PA as Phase1Analyzer
    participant SM as SemanticMatcher
    participant LG as LangGraph
    participant LLM as LLM (GPT-4)
    participant PI as Phase2Interviewer
    
    U->>UI: Ingresa Oferta + CV
    UI->>PA: analyze(oferta, cv)
    
    alt LangGraph Activado
        PA->>LG: run_phase1_graph()
        LG->>LLM: Nodo 1: Extraer requisitos
        LLM-->>LG: Lista de requisitos
        LG->>SM: Nodo 2: Indexar CV
        SM-->>LG: CV vectorizado
        LG->>LLM: Nodo 3: Matching con evidencia
        LLM-->>LG: Matches + confianza
        LG->>LG: Nodo 4: Calcular score
        LG-->>PA: Phase1Result
    else Flujo Tradicional
        PA->>LLM: Extraer requisitos
        LLM-->>PA: Lista de requisitos
        PA->>SM: Indexar CV (si habilitado)
        SM-->>PA: Evidencia semÃ¡ntica
        PA->>LLM: Matching CV-Requisitos
        LLM-->>PA: Matches + confianza
        PA->>PA: Calcular score
    end
    
    PA-->>UI: Phase1Result
    
    alt Score > 0 y hay requisitos faltantes
        UI->>PI: conduct_interview()
        PI->>LLM: Generar preguntas
        LLM-->>PI: Preguntas
        PI-->>UI: Mostrar preguntas
        U->>UI: Responde preguntas
        UI->>PI: Evaluar respuestas
        PI->>LLM: Evaluar cada respuesta
        LLM-->>PI: EvaluaciÃ³n
        PI-->>UI: Resultado final
    end
    
    UI-->>U: Resultado + Evidencia
```

### 5.3 Flujo del Sistema RAG Conversacional

```mermaid
flowchart TB
    subgraph "Entrada"
        Q[Consulta Usuario<br/>"Â¿Por quÃ© me rechazaron?"]
    end
    
    subgraph "Retrieval"
        VS[(VectorStore<br/>FAISS)]
        EMB[OpenAI<br/>Embeddings]
        Q --> EMB
        EMB --> VS
        VS --> |Top K docs| DOCS[Documentos<br/>Relevantes]
    end
    
    subgraph "Augmentation"
        CTX[Formatear<br/>Contexto]
        DOCS --> CTX
    end
    
    subgraph "Generation"
        PROMPT[System Prompt<br/>+ Contexto + Query]
        LLM[LLM<br/>GPT-4]
        CTX --> PROMPT
        Q --> PROMPT
        PROMPT --> LLM
    end
    
    subgraph "Salida"
        R[Respuesta<br/>Contextualizada]
        LLM --> R
    end
    
    style Q fill:#e1f5fe
    style R fill:#c8e6c9
    style VS fill:#fff3e0
    style LLM fill:#f3e5f5
```

### 5.4 ActivaciÃ³n/DesactivaciÃ³n de Funcionalidades Opcionales

```mermaid
flowchart TB
    subgraph "ConfiguraciÃ³n UI"
        T1[Toggle LangGraph]
        T2[Toggle Embeddings]
    end
    
    subgraph "Phase1Analyzer Initialization"
        INIT[__init__]
        T1 --> |use_langgraph=true/false| INIT
        T2 --> |use_semantic_matching=true/false| INIT
    end
    
    subgraph "LangGraph Path"
        LG_INIT[_init_langgraph]
        LG_GRAPH[create_phase1_graph]
        LG_RUN[_analyze_with_langgraph]
    end
    
    subgraph "Embeddings Path"
        SM_INIT[SemanticMatcher]
        SM_INDEX[index_cv]
        SM_FIND[find_evidence]
    end
    
    subgraph "Traditional Path"
        TRAD[_analyze_traditional]
    end
    
    INIT --> |if use_langgraph| LG_INIT
    LG_INIT --> LG_GRAPH
    
    INIT --> |if use_semantic_matching| SM_INIT
    
    subgraph "Runtime Decision"
        ANALYZE[analyze]
        ANALYZE --> |use_langgraph=True| LG_RUN
        ANALYZE --> |use_langgraph=False| TRAD
        LG_RUN --> |usa| SM_INDEX
        TRAD --> |if semantic_matcher| SM_INDEX
        SM_INDEX --> SM_FIND
    end
    
    style T1 fill:#bbdefb
    style T2 fill:#bbdefb
    style LG_RUN fill:#c8e6c9
    style TRAD fill:#fff3e0
```

### 5.5 InteracciÃ³n Frontend-Backend-LangChain

```mermaid
flowchart LR
    subgraph "Frontend Layer"
        ST[Streamlit App]
        TABS[Tabs: EvaluaciÃ³n | Historial]
    end
    
    subgraph "Backend Layer"
        PA[Phase1Analyzer]
        CE[CandidateEvaluator]
        CB[HistoryChatbot]
    end
    
    subgraph "LangChain Layer"
        LLM[LLM<br/>Structured Output]
        EMB[Embeddings<br/>text-embedding-3-small]
        CHAIN[Chains<br/>prompt | llm]
    end
    
    subgraph "Storage Layer"
        UM[(UserMemory<br/>JSON)]
        VS[(VectorStore<br/>FAISS)]
    end
    
    ST --> |Tab 1| PA
    ST --> |Tab 2| CB
    
    PA --> LLM
    PA --> EMB
    CE --> PA
    
    CB --> LLM
    CB --> VS
    CB --> UM
    
    EMB --> VS
    PA --> UM
    
    style ST fill:#e3f2fd
    style LLM fill:#f3e5f5
    style VS fill:#fff8e1
```

### 5.6 Pipeline de Procesamiento de Documentos

```mermaid
flowchart TB
    subgraph "Entrada de Documentos"
        PDF[PDF Upload]
        URL[URL Scraping]
        TXT[Texto Directo]
    end
    
    subgraph "ExtracciÃ³n"
        PDF_EX[pypdf<br/>extract_text_from_pdf]
        URL_EX[BeautifulSoup<br/>scrape_job_offer_url]
        PDF --> PDF_EX
        URL --> URL_EX
    end
    
    subgraph "NormalizaciÃ³n"
        CLEAN[Limpieza de texto<br/>- Eliminar HTML<br/>- Normalizar espacios]
        PDF_EX --> CLEAN
        URL_EX --> CLEAN
        TXT --> CLEAN
    end
    
    subgraph "Chunking (para CV)"
        SPLIT[RecursiveTextSplitter<br/>500 chars, 50 overlap]
        CLEAN --> |CV| SPLIT
    end
    
    subgraph "VectorizaciÃ³n"
        EMB[OpenAI Embeddings<br/>text-embedding-3-small]
        FAISS[(FAISS Index)]
        SPLIT --> EMB
        EMB --> FAISS
    end
    
    subgraph "Procesamiento LLM"
        REQ[ExtracciÃ³n Requisitos<br/>Structured Output]
        MATCH[Matching CV<br/>+ Evidencia SemÃ¡ntica]
        CLEAN --> |Oferta| REQ
        REQ --> MATCH
        FAISS --> |Evidencia| MATCH
    end
    
    style PDF fill:#ffcdd2
    style URL fill:#c8e6c9
    style FAISS fill:#fff3e0
```

---

## 6. LangChain como Pilar TecnolÃ³gico

### 6.1 ImplementaciÃ³n de Vanguardia

Este proyecto representa una implementaciÃ³n **de vanguardia** de LangChain, utilizando sus capacidades mÃ¡s avanzadas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LANGCHAIN EN EL PROYECTO                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STRUCTURED OUTPUT                                               â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚   â”‚
â”‚  â”‚  â€¢ llm.with_structured_output(PydanticModel)                     â”‚   â”‚
â”‚  â”‚  â€¢ Garantiza respuestas JSON vÃ¡lidas                             â”‚   â”‚
â”‚  â”‚  â€¢ Elimina necesidad de parsing manual                           â”‚   â”‚
â”‚  â”‚  â€¢ Tipado fuerte con Pydantic                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LANGGRAPH (Multi-Agente)                                        â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚   â”‚
â”‚  â”‚  â€¢ StateGraph con estado tipado                                  â”‚   â”‚
â”‚  â”‚  â€¢ Nodos especializados (Extractor, Embedder, Matcher, Scorer)   â”‚   â”‚
â”‚  â”‚  â€¢ Flujo declarativo con edges                                   â”‚   â”‚
â”‚  â”‚  â€¢ Streaming de estados intermedios                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RAG (Retrieval Augmented Generation)                            â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚   â”‚
â”‚  â”‚  â€¢ FAISS VectorStore para embeddings                             â”‚   â”‚
â”‚  â”‚  â€¢ OpenAIEmbeddings (text-embedding-3-small)                     â”‚   â”‚
â”‚  â”‚  â€¢ BÃºsqueda por similitud con scores                             â”‚   â”‚
â”‚  â”‚  â€¢ Contexto dinÃ¡mico para respuestas                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LANGSMITH (Observabilidad)                                      â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚   â”‚
â”‚  â”‚  â€¢ Tracing automÃ¡tico de todas las llamadas LLM                  â”‚   â”‚
â”‚  â”‚  â€¢ Feedback loop para mejora continua                            â”‚   â”‚
â”‚  â”‚  â€¢ MÃ©tricas de latencia y tokens                                 â”‚   â”‚
â”‚  â”‚  â€¢ Debugging de prompts y respuestas                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Uso de Chains

El proyecto utiliza **chains** de LangChain para crear pipelines de procesamiento:

```python
# Ejemplo: Chain para extracciÃ³n de requisitos
from langchain_core.prompts import ChatPromptTemplate

# 1. Definir el prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", EXTRACT_REQUIREMENTS_PROMPT),
    ("human", "{job_offer}")
])

# 2. Crear LLM con Structured Output
extraction_llm = llm.with_structured_output(RequirementsExtractionResponse)

# 3. Construir chain con operador pipe
chain = prompt | extraction_llm

# 4. Ejecutar
result: RequirementsExtractionResponse = chain.invoke({"job_offer": job_offer_text})
```

**Beneficios de este enfoque**:
- ComposiciÃ³n declarativa con `|` (pipe operator)
- Tipado fuerte con Pydantic
- ReutilizaciÃ³n de componentes
- FÃ¡cil testing y debugging

### 6.3 ImplementaciÃ³n de Agents con LangGraph

```python
# UbicaciÃ³n: src/evaluator/core/graph.py

from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
from operator import add

# 1. Definir estado compartido
class Phase1State(TypedDict):
    job_offer: str
    cv: str
    requirements: List[dict]
    semantic_evidence: Dict[str, dict]
    matches: List[dict]
    fulfilled_requirements: List[Requirement]
    unfulfilled_requirements: List[Requirement]
    score: float
    messages: Annotated[List[str], add]  # Acumulador para streaming

# 2. Crear nodos especializados
def create_extract_node(llm):
    def extract_requirements(state: Phase1State) -> dict:
        # Agente especializado en extracciÃ³n
        result = extraction_chain.invoke({"job_offer": state["job_offer"]})
        return {"requirements": result.requirements}
    return extract_requirements

def create_embed_node(semantic_matcher):
    def embed_cv(state: Phase1State) -> dict:
        # Agente especializado en embeddings
        semantic_matcher.index_cv(state["cv"])
        evidence = semantic_matcher.find_all_evidence(state["requirements"])
        return {"semantic_evidence": evidence}
    return embed_cv

# 3. Construir grafo
graph = StateGraph(Phase1State)
graph.add_node("extract_requirements", extract_node)
graph.add_node("embed_cv", embed_node)
graph.add_node("semantic_match", match_node)
graph.add_node("calculate_score", score_node)

# 4. Definir flujo
graph.set_entry_point("extract_requirements")
graph.add_edge("extract_requirements", "embed_cv")
graph.add_edge("embed_cv", "semantic_match")
graph.add_edge("semantic_match", "calculate_score")
graph.add_edge("calculate_score", END)

# 5. Compilar y ejecutar
compiled_graph = graph.compile()
result = compiled_graph.invoke(initial_state)
```

### 6.4 Embeddings y VectorStore

```python
# UbicaciÃ³n: src/evaluator/core/embeddings.py

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

class SemanticMatcher:
    def __init__(self):
        # Inicializar embeddings con modelo eficiente
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self._vectorstore: Optional[FAISS] = None
    
    def index_cv(self, cv_text: str) -> int:
        """Vectoriza el CV para bÃºsqueda semÃ¡ntica"""
        # Dividir en chunks
        chunks = self._split_cv_into_chunks(cv_text)
        
        # Crear vectorstore en memoria
        self._vectorstore = FAISS.from_texts(chunks, self.embeddings)
        
        return len(chunks)
    
    def find_evidence(self, requirement: str, k: int = 3) -> List[Tuple[str, float]]:
        """Busca evidencia semÃ¡ntica para un requisito"""
        results = self._vectorstore.similarity_search_with_score(requirement, k=k)
        
        # Convertir distancia L2 a similitud
        return [(doc.page_content, 1 / (1 + score)) for doc, score in results]
```

### 6.5 Ventajas Competitivas vs ImplementaciÃ³n Tradicional

| Aspecto | ImplementaciÃ³n Tradicional | Con LangChain |
|---------|---------------------------|---------------|
| **Parsing JSON** | Regex, try/catch, errores frecuentes | Structured Output garantizado |
| **Multi-proveedor** | CÃ³digo especÃ­fico por proveedor | Factory abstracta unificada |
| **OrquestaciÃ³n** | if/else anidados, difÃ­cil de mantener | LangGraph declarativo |
| **BÃºsqueda semÃ¡ntica** | ImplementaciÃ³n manual de embeddings | FAISS integrado |
| **Observabilidad** | Logging manual | LangSmith automÃ¡tico |
| **Prompts** | Strings hardcoded | Templates reutilizables |
| **Testing** | Mocks complejos | Chains testeables |

---

## 7. Sistema RAG Conversacional

### 7.1 Arquitectura del RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG ARCHITECTURE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                     INGESTION PIPELINE                        â”‚      â”‚
â”‚  â”‚                                                                â”‚      â”‚
â”‚  â”‚  EnrichedEvaluation â”€â”€â–º Searchable Text â”€â”€â–º Embeddings â”€â”€â–º FAISS â”‚   â”‚
â”‚  â”‚                                                                â”‚      â”‚
â”‚  â”‚  Campos indexados:                                             â”‚      â”‚
â”‚  â”‚  â€¢ job_offer_title      â€¢ gap_summary                         â”‚      â”‚
â”‚  â”‚  â€¢ score                â€¢ strengths_summary                   â”‚      â”‚
â”‚  â”‚  â€¢ status               â€¢ fulfilled_requirements              â”‚      â”‚
â”‚  â”‚  â€¢ rejection_reason     â€¢ unfulfilled_requirements            â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                     QUERY PIPELINE                            â”‚      â”‚
â”‚  â”‚                                                                â”‚      â”‚
â”‚  â”‚  User Query â”€â”€â–º Embedding â”€â”€â–º FAISS Search â”€â”€â–º Top-K Docs     â”‚      â”‚
â”‚  â”‚                                       â”‚                        â”‚      â”‚
â”‚  â”‚                                       â–¼                        â”‚      â”‚
â”‚  â”‚                              Context Formatting                â”‚      â”‚
â”‚  â”‚                                       â”‚                        â”‚      â”‚
â”‚  â”‚                                       â–¼                        â”‚      â”‚
â”‚  â”‚  System Prompt + Context + Query â”€â”€â–º LLM â”€â”€â–º Response         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Modelo de Datos Enriquecido

```python
class EnrichedEvaluation(BaseModel):
    """Modelo optimizado para bÃºsqueda RAG"""
    
    # IdentificaciÃ³n
    evaluation_id: str              # UUID Ãºnico
    user_id: str                    # ID del usuario
    timestamp: str                  # ISO timestamp
    
    # Estado
    score: float                    # 0-100
    status: Literal["approved", "rejected", "phase1_only"]
    phase_completed: Literal["phase1", "phase2"]
    
    # Oferta (optimizado para RAG)
    job_offer_title: str            # TÃ­tulo extraÃ­do
    job_offer_summary: str          # Primeros 500 chars
    total_requirements: int
    obligatory_requirements: int
    optional_requirements: int
    
    # Resultados detallados
    fulfilled_count: int
    unfulfilled_obligatory_count: int
    unfulfilled_optional_count: int
    
    # Campos narrativos para bÃºsqueda
    rejection_reason: Optional[str]
    gap_summary: Optional[str]      # "Falta: Python, Docker..."
    strengths_summary: Optional[str] # "Cumple: React, Node..."
    
    # Texto para embeddings
    searchable_text: str            # ConcatenaciÃ³n optimizada
    
    # Proveedor
    provider: str
    model: str
```

### 7.3 Flujo de Consulta RAG

```python
# UbicaciÃ³n: src/evaluator/rag/chatbot.py

class HistoryChatbot:
    def query(self, question: str, k: int = 5) -> str:
        # 1. Buscar documentos relevantes
        docs = self.vectorstore.search(question, k=k)
        
        # 2. Formatear contexto
        context = self._format_context(docs)
        
        # 3. Crear prompt con contexto
        prompt = ChatPromptTemplate.from_messages([
            ("system", HISTORY_CHATBOT_PROMPT),
            ("human", "{question}")
        ])
        
        # 4. Generar respuesta
        chain = prompt | self.llm
        response = chain.invoke({"context": context, "question": question})
        
        return response.content
```

### 7.4 Ejemplos de Consultas Soportadas

| Tipo de Consulta | Ejemplo | Respuesta |
|------------------|---------|-----------|
| **AnÃ¡lisis de rechazo** | "Â¿Por quÃ© me rechazaron la Ãºltima vez?" | Detalles de requisitos obligatorios no cumplidos |
| **IdentificaciÃ³n de fortalezas** | "Â¿CuÃ¡les son mis puntos fuertes?" | Requisitos cumplidos consistentemente |
| **AnÃ¡lisis de brechas** | "Â¿QuÃ© skills me faltan?" | Requisitos no cumplidos frecuentes |
| **ComparaciÃ³n temporal** | "Compara mis Ãºltimas evaluaciones" | EvoluciÃ³n de score y requisitos |
| **EstadÃ­sticas** | "Â¿CuÃ¡l es mi score promedio?" | CÃ¡lculo sobre historial |

---

## 8. Funcionalidades Premium Opcionales

### 8.1 Toggle de Funcionalidades

El sistema ofrece dos funcionalidades premium que pueden activarse/desactivarse independientemente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FUNCIONALIDADES PREMIUM                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ðŸ”„ LANGGRAPH MULTI-AGENTE                                       â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  ACTIVADO:                      DESACTIVADO:                     â”‚   â”‚
â”‚  â”‚  â€¢ Grafo de 4 nodos             â€¢ Flujo secuencial              â”‚   â”‚
â”‚  â”‚  â€¢ Estado compartido            â€¢ Llamadas directas             â”‚   â”‚
â”‚  â”‚  â€¢ Streaming de progreso        â€¢ Sin estado intermedio         â”‚   â”‚
â”‚  â”‚  â€¢ Agentes especializados       â€¢ CÃ³digo mÃ¡s simple             â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Toggle: use_langgraph=True/False                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ðŸ” EMBEDDINGS SEMÃNTICOS                                        â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  ACTIVADO:                      DESACTIVADO:                     â”‚   â”‚
â”‚  â”‚  â€¢ CV indexado en FAISS         â€¢ LLM analiza CV completo       â”‚   â”‚
â”‚  â”‚  â€¢ BÃºsqueda por similitud       â€¢ Sin pre-filtrado              â”‚   â”‚
â”‚  â”‚  â€¢ Evidencia con score          â€¢ Solo evidencia textual        â”‚   â”‚
â”‚  â”‚  â€¢ Pistas semÃ¡nticas al LLM     â€¢ Matching directo              â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Toggle: use_semantic_matching=True/False                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Impacto Diferencial

| Funcionalidad | Sin Premium | Con Premium | Impacto |
|---------------|-------------|-------------|---------|
| **LangGraph** | Flujo secuencial | OrquestaciÃ³n multi-agente | Mayor modularidad y trazabilidad |
| **Embeddings** | Matching directo | BÃºsqueda semÃ¡ntica | +15-20% precisiÃ³n en evidencia |
| **Combinado** | Baseline | Full premium | AnÃ¡lisis mÃ¡s estructurado y preciso |

### 8.3 Logs de ActivaciÃ³n

Cuando se activa/desactiva cada funcionalidad, el sistema genera logs informativos:

```bash
# LangGraph ACTIVADO
[21:24:29] ðŸ”„ [CONFIG] LangGraph Multi-Agente: ACTIVADO â†’ OrquestaciÃ³n avanzada

# LangGraph DESACTIVADO
[21:24:29] ðŸ”„ [CONFIG] LangGraph Multi-Agente: DESACTIVADO â†’ Flujo tradicional

# Embeddings ACTIVADO
[21:24:29] ðŸ” [CONFIG] Embeddings SemÃ¡nticos: ACTIVADO â†’ BÃºsqueda vectorial FAISS

# Embeddings DESACTIVADO
[21:24:29] ðŸ” [CONFIG] Embeddings SemÃ¡nticos: DESACTIVADO â†’ Matching directo con LLM
```

---

## 9. Pipeline de Procesamiento

### 9.1 Flujo End-to-End

```mermaid
flowchart TB
    subgraph "1. INGESTA"
        A1[PDF] --> EXT1[pypdf extract]
        A2[URL] --> EXT2[BeautifulSoup scrape]
        A3[Texto] --> EXT3[Directo]
        EXT1 --> CLEAN[NormalizaciÃ³n]
        EXT2 --> CLEAN
        EXT3 --> CLEAN
    end
    
    subgraph "2. ANÃLISIS FASE 1"
        CLEAN --> REQ[ExtracciÃ³n Requisitos<br/>Structured Output]
        REQ --> EMB{Embeddings<br/>habilitados?}
        EMB -->|SÃ­| FAISS[Indexar CV<br/>FAISS]
        FAISS --> MATCH
        EMB -->|No| MATCH[Matching<br/>CV-Requisitos]
        MATCH --> SCORE[Calcular Score<br/>+ Confianza]
    end
    
    subgraph "3. DECISIÃ“N"
        SCORE --> DEC{Score > 0?}
        DEC -->|No| REJECT[Rechazado<br/>Fin]
        DEC -->|SÃ­| MISS{Â¿Hay requisitos<br/>faltantes?}
        MISS -->|No| APPROVE[Aprobado<br/>Fin]
        MISS -->|SÃ­| P2[Continuar<br/>Fase 2]
    end
    
    subgraph "4. ANÃLISIS FASE 2"
        P2 --> QGEN[Generar Preguntas<br/>por requisito]
        QGEN --> INTERVIEW[Entrevista<br/>Interactiva]
        INTERVIEW --> EVAL[Evaluar<br/>Respuestas]
        EVAL --> RESCORE[Re-calcular<br/>Score Final]
        RESCORE --> FINAL[Resultado<br/>Final]
    end
    
    subgraph "5. PERSISTENCIA"
        REJECT --> SAVE[Guardar<br/>EnrichedEvaluation]
        APPROVE --> SAVE
        FINAL --> SAVE
        SAVE --> RAG[Indexar en<br/>VectorStore]
    end
```

### 9.2 Procesamiento de Requisitos

```python
# Modelo Pydantic para Structured Output
class RequirementsExtractionResponse(BaseModel):
    """Respuesta estructurada del LLM"""
    requirements: List[ExtractedRequirement]

class ExtractedRequirement(BaseModel):
    description: str = Field(..., description="DescripciÃ³n exacta del requisito")
    type: Literal["obligatory", "optional"] = Field(...)

# Chain de extracciÃ³n
chain = prompt | llm.with_structured_output(RequirementsExtractionResponse)
result = chain.invoke({"job_offer": job_offer_text})

# Resultado: Lista tipada y validada
for req in result.requirements:
    print(f"[{req.type}] {req.description}")
```

### 9.3 Procesamiento de Matching

```python
# Modelo para matching
class RequirementMatch(BaseModel):
    requirement_description: str
    fulfilled: bool
    found_in_cv: bool
    evidence: Optional[str]
    confidence: Literal["high", "medium", "low"]
    reasoning: str

class CVMatchingResponse(BaseModel):
    matches: List[RequirementMatch]
    analysis_summary: str

# El LLM retorna directamente objetos tipados
result: CVMatchingResponse = matching_chain.invoke({
    "cv": cv_text,
    "requirements_list": formatted_requirements
})
```

---

## 10. Arquitectura de CÃ³digo

### 10.1 Estructura de Directorios

```
src/evaluator/
â”œâ”€â”€ __init__.py                 # Exports pÃºblicos del paquete
â”œâ”€â”€ models.py                   # Modelos Pydantic (datos + Structured Output)
â”‚
â”œâ”€â”€ core/                       # LÃ³gica de negocio principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluator.py           # Orquestador principal
â”‚   â”œâ”€â”€ analyzer.py            # Fase 1: ExtracciÃ³n + Matching
â”‚   â”œâ”€â”€ interviewer.py         # Fase 2: Entrevista interactiva
â”‚   â”œâ”€â”€ graph.py               # LangGraph multi-agente
â”‚   â”œâ”€â”€ embeddings.py          # SemanticMatcher con FAISS
â”‚   â””â”€â”€ logging_config.py      # Sistema de logging operacional
â”‚
â”œâ”€â”€ llm/                        # AbstracciÃ³n de LLMs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ factory.py             # Factory multi-proveedor
â”‚   â””â”€â”€ prompts.py             # Prompts centralizados
â”‚
â”œâ”€â”€ rag/                        # Sistema RAG para historial
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vectorstore.py         # HistoryVectorStore
â”‚   â””â”€â”€ chatbot.py             # HistoryChatbot
â”‚
â”œâ”€â”€ storage/                    # Persistencia
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ memory.py              # UserMemory + EnrichedEvaluation
â”‚
â”œâ”€â”€ extraction/                 # Ingesta de documentos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf.py                 # ExtracciÃ³n de PDFs
â”‚   â””â”€â”€ url.py                 # Scraping de URLs
â”‚
â””â”€â”€ processing/                 # Utilidades
    â”œâ”€â”€ __init__.py
    â””â”€â”€ validation.py          # Funciones de validaciÃ³n
```

### 10.2 Principios SOLID Aplicados

| Principio | AplicaciÃ³n | Ejemplo |
|-----------|------------|---------|
| **S**ingle Responsibility | Cada mÃ³dulo tiene una responsabilidad | `analyzer.py` solo hace anÃ¡lisis |
| **O**pen/Closed | Extensible sin modificar cÃ³digo existente | Nuevos proveedores LLM vÃ­a Factory |
| **L**iskov Substitution | Subtipos intercambiables | Todos los LLMs implementan BaseChatModel |
| **I**nterface Segregation | Interfaces especÃ­ficas | Pydantic models por operaciÃ³n |
| **D**ependency Inversion | Depender de abstracciones | `LLMFactory` abstrae proveedores |

### 10.3 SeparaciÃ³n de Responsabilidades

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPAS DE RESPONSABILIDAD                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  PRESENTACIÃ“N (app/)                                                     â”‚
â”‚  â””â”€â”€ streamlit_app.py                                                    â”‚
â”‚      â€¢ UI/UX                                                             â”‚
â”‚      â€¢ Manejo de estado de sesiÃ³n                                        â”‚
â”‚      â€¢ VisualizaciÃ³n de resultados                                       â”‚
â”‚                                                                          â”‚
â”‚  ORQUESTACIÃ“N (core/evaluator.py)                                        â”‚
â”‚  â””â”€â”€ CandidateEvaluator                                                  â”‚
â”‚      â€¢ Coordina Fase 1 y Fase 2                                          â”‚
â”‚      â€¢ Maneja flujo de decisiones                                        â”‚
â”‚      â€¢ Integra con LangSmith                                             â”‚
â”‚                                                                          â”‚
â”‚  DOMINIO (core/analyzer.py, core/interviewer.py)                         â”‚
â”‚  â””â”€â”€ Phase1Analyzer, Phase2Interviewer                                   â”‚
â”‚      â€¢ LÃ³gica de negocio especÃ­fica                                      â”‚
â”‚      â€¢ ExtracciÃ³n, matching, entrevista                                  â”‚
â”‚                                                                          â”‚
â”‚  SERVICIOS (llm/, rag/, core/embeddings.py)                              â”‚
â”‚  â””â”€â”€ LLMFactory, SemanticMatcher, HistoryChatbot                         â”‚
â”‚      â€¢ AbstracciÃ³n de servicios externos                                 â”‚
â”‚      â€¢ Embeddings, bÃºsqueda, LLM calls                                   â”‚
â”‚                                                                          â”‚
â”‚  PERSISTENCIA (storage/memory.py)                                        â”‚
â”‚  â””â”€â”€ UserMemory                                                          â”‚
â”‚      â€¢ Guardar/cargar evaluaciones                                       â”‚
â”‚      â€¢ ConversiÃ³n de formatos                                            â”‚
â”‚                                                                          â”‚
â”‚  INFRAESTRUCTURA (extraction/, processing/)                              â”‚
â”‚  â””â”€â”€ pdf.py, url.py, validation.py                                       â”‚
â”‚      â€¢ Utilidades de bajo nivel                                          â”‚
â”‚      â€¢ ExtracciÃ³n de documentos                                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 11. Sistema de Logging Operacional

### 11.1 Arquitectura del Logger

```python
# UbicaciÃ³n: src/evaluator/core/logging_config.py

class OperationalLogger:
    """
    Logger singleton para trazabilidad operacional.
    Proporciona logs informativos con timestamps y categorÃ­as.
    """
    
    # CategorÃ­as de logs
    def config_langgraph(self, enabled: bool)    # Estado de LangGraph
    def config_semantic(self, enabled: bool)     # Estado de Embeddings
    def config_provider(self, provider, model)   # Proveedor LLM
    
    def phase1_start(self, mode)                 # Inicio de Fase 1
    def extraction_complete(self, total, obl, opt)  # Requisitos extraÃ­dos
    def semantic_indexing(self, chunks)          # CV indexado
    def matching_complete(self, fulfilled, unfulfilled, score)
    def phase1_complete(self, discarded, score, duration_ms)
    
    def langgraph_node(self, node_name, status)  # Nodo LangGraph
    
    def rag_indexed(self, doc_count)             # RAG indexado
    def rag_query(self, retrieved)               # Consulta RAG
    
    def evaluation_saved(self, user_id, type)    # Persistencia
```

### 11.2 Ejemplo de Salida

```bash
============================================================
[21:24:29] ðŸ¤– [CONFIG] LLM: OPENAI/gpt-4
[21:24:29] ðŸ”„ [CONFIG] LangGraph Multi-Agente: ACTIVADO â†’ OrquestaciÃ³n avanzada
[21:24:29] ðŸ” [CONFIG] Embeddings SemÃ¡nticos: ACTIVADO â†’ BÃºsqueda vectorial FAISS
============================================================
[21:24:30] ðŸ“‹ [FASE 1] Iniciando anÃ¡lisis CV vs Oferta â†’ Modo: LangGraph Multi-Agente
[21:24:31] âš™ï¸ [LANGGRAPH] Nodo 'extract_requirements' â†’ ejecutando
[21:24:32] âœ… [EXTRACCIÃ“N] Requisitos extraÃ­dos: 7 (Obligatorios: 4, Opcionales: 3)
[21:24:32] âš™ï¸ [LANGGRAPH] Nodo 'embed_cv' â†’ ejecutando
[21:24:33] ðŸ“Š [EMBEDDINGS] CV indexado en FAISS: 12 chunks vectorizados
[21:24:33] ðŸŽ¯ [EMBEDDINGS] Evidencia semÃ¡ntica: 5/7 requisitos con matches
[21:24:33] âš™ï¸ [LANGGRAPH] Nodo 'semantic_match' â†’ ejecutando
[21:24:35] âš™ï¸ [LANGGRAPH] Nodo 'calculate_score' â†’ ejecutando
[21:24:35] ðŸ“Š [MATCHING] Resultado: 5 cumplidos, 2 no cumplidos â†’ Score: 71.4%
[21:24:35] ðŸ [FASE 1] Completada (5230ms) â†’ Estado: APTO, Score: 71.4%
[21:24:36] ðŸ’¾ [STORAGE] EvaluaciÃ³n enriched guardada para usuario 'carlos'
============================================================
```

### 11.3 IntegraciÃ³n con Componentes

```python
# En Phase1Analyzer
from .logging_config import get_operational_logger

class Phase1Analyzer:
    def __init__(self, ...):
        self._op_logger = get_operational_logger()
        
        # Log de configuraciÃ³n
        self._op_logger.config_provider(provider, model_name)
        self._op_logger.config_langgraph(use_langgraph)
        self._op_logger.config_semantic(use_semantic_matching)
    
    def analyze(self, job_offer, cv):
        start_time = time.time()
        
        self._op_logger.phase1_start(mode="langgraph" if self.use_langgraph else "traditional")
        
        # ... anÃ¡lisis ...
        
        duration_ms = int((time.time() - start_time) * 1000)
        self._op_logger.phase1_complete(discarded, score, duration_ms)
```

---

## 12. GestiÃ³n de Configuraciones

### 12.1 Variables de Entorno

```bash
# .env (ejemplo)

# Obligatorio: API Key del proveedor principal
OPENAI_API_KEY=sk-...

# Opcionales: Proveedores adicionales
GOOGLE_API_KEY=...
ANTHROPIC_API_KEY=...

# Opcional: LangSmith para trazabilidad
LANGSMITH_API_KEY=...
LANGCHAIN_PROJECT=velora-evaluator
```

### 12.2 ConfiguraciÃ³n en Tiempo de EjecuciÃ³n

```python
# Desde cÃ³digo
analyzer = Phase1Analyzer(
    provider="openai",           # Proveedor LLM
    model_name="gpt-4",          # Modelo
    temperature=0.1,             # Temperatura (baja para precisiÃ³n)
    use_semantic_matching=True,  # Toggle embeddings
    use_langgraph=True           # Toggle multi-agente
)

# Desde UI (Streamlit)
# Los toggles se configuran en la secciÃ³n "Opciones Avanzadas"
```

### 12.3 ConfiguraciÃ³n de Modelos por Proveedor

```python
class LLMFactory:
    OPENAI_MODELS = ["gpt-4", "gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"]
    GOOGLE_MODELS = ["gemini-pro", "gemini-1.5-pro", "gemini-1.5-flash"]
    ANTHROPIC_MODELS = ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
```

---

## 13. Estrategias de Escalabilidad

### 13.1 Escalabilidad Horizontal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ESTRATEGIA DE ESCALABILIDAD                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ACTUAL (Monolito)                 FUTURO (Microservicios)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚  Streamlit  â”‚                   â”‚   API GW    â”‚                      â”‚
â”‚  â”‚  + Backend  â”‚        â”€â”€â”€â–º       â”‚   (FastAPI) â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                           â”‚                              â”‚
â”‚                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                               â–¼           â–¼           â–¼                 â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                         â”‚ Eval    â”‚ â”‚  RAG    â”‚ â”‚ Storage â”‚            â”‚
â”‚                         â”‚ Service â”‚ â”‚ Service â”‚ â”‚ Service â”‚            â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 13.2 Puntos de ExtensiÃ³n

| Punto | Mecanismo | Ejemplo |
|-------|-----------|---------|
| **Nuevos proveedores LLM** | Factory Pattern | AÃ±adir Cohere, Mistral |
| **Nuevos formatos de entrada** | Extraction module | AÃ±adir DOCX, imÃ¡genes |
| **Nuevas fuentes de historial** | Repository Pattern | Migrar a PostgreSQL |
| **Nuevas mÃ©tricas** | Logger extensible | AÃ±adir mÃ©tricas de negocio |

### 13.3 Optimizaciones de Rendimiento

```python
# 1. Embeddings eficientes
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")  # MÃ¡s rÃ¡pido que ada-002

# 2. Chunking optimizado
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,    # Ã“ptimo para CVs
    chunk_overlap=50   # Continuidad semÃ¡ntica
)

# 3. Batch processing (futuro)
# vectorstore.add_texts(texts, batch_size=100)

# 4. Caching de embeddings
# @lru_cache para requisitos frecuentes
```

---

## 14. GuÃ­a de Despliegue

### 14.1 Requisitos del Sistema

```yaml
Requisitos MÃ­nimos:
  - Python: 3.9+
  - RAM: 4 GB
  - Disco: 500 MB
  - Red: Acceso a APIs de LLM

Requisitos Recomendados:
  - Python: 3.11+
  - RAM: 8 GB
  - Disco: 2 GB (para vectorstores)
  - GPU: No requerida (embeddings via API)
```

### 14.2 InstalaciÃ³n

```bash
# 1. Clonar repositorio
git clone <repo_url>
cd velora_auto

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o: venv\Scripts\activate  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con API keys

# 5. Ejecutar aplicaciÃ³n
streamlit run app/streamlit_app.py
```

### 14.3 Despliegue en ProducciÃ³n

```yaml
# docker-compose.yml (ejemplo)
version: '3.8'
services:
  evaluator:
    build: .
    ports:
      - "8501:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
    volumes:
      - ./data:/app/data
```

---

## 15. MÃ©tricas y Observabilidad

### 15.1 MÃ©tricas Disponibles

| MÃ©trica | Fuente | DescripciÃ³n |
|---------|--------|-------------|
| **Latencia Fase 1** | Logger | Tiempo total de anÃ¡lisis |
| **Requisitos extraÃ­dos** | Logger | Count por tipo |
| **Score promedio** | UserMemory | HistÃ³rico por usuario |
| **Chunks indexados** | Logger | Eficiencia de chunking |
| **Tokens consumidos** | LangSmith | Costo por evaluaciÃ³n |

### 15.2 IntegraciÃ³n con LangSmith

```python
# ConfiguraciÃ³n automÃ¡tica
from evaluator.llm.factory import configure_langsmith

# Habilitar trazabilidad
langsmith_client = configure_langsmith(project_name="velora-evaluator")

# Todas las llamadas LLM son trazadas automÃ¡ticamente
# Ver en: https://smith.langchain.com/
```

### 15.3 Dashboard de Monitoreo (Futuro)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DASHBOARD DE MONITOREO                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Evaluaciones/dÃ­a â”‚  â”‚ Score Promedio  â”‚  â”‚ Latencia P95    â”‚         â”‚
â”‚  â”‚      127         â”‚  â”‚     68.5%       â”‚  â”‚    4.2s         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Tokens consumidos (Ãºltimos 7 dÃ­as)                               â”‚   â”‚
â”‚  â”‚ â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‹ ApÃ©ndice: Glosario TÃ©cnico

| TÃ©rmino | DefiniciÃ³n |
|---------|------------|
| **Chain** | Pipeline de LangChain que conecta prompt + LLM |
| **Structured Output** | Capacidad de LangChain para garantizar JSON vÃ¡lido |
| **LangGraph** | LibrerÃ­a para crear grafos de agentes con estado |
| **FAISS** | LibrerÃ­a de Facebook para bÃºsqueda vectorial eficiente |
| **RAG** | Retrieval Augmented Generation - enriquecer LLM con contexto |
| **VectorStore** | Base de datos para embeddings (representaciones numÃ©ricas) |
| **Embedding** | RepresentaciÃ³n vectorial de texto para bÃºsqueda semÃ¡ntica |
| **LangSmith** | Plataforma de observabilidad para aplicaciones LangChain |
| **Pydantic** | LibrerÃ­a Python para validaciÃ³n de datos con tipos |
| **Singleton** | PatrÃ³n de diseÃ±o que garantiza una Ãºnica instancia |
| **Factory** | PatrÃ³n de diseÃ±o para crear objetos sin especificar clase |

---

## ðŸ“ž Contacto y Soporte

Para consultas tÃ©cnicas o soporte:
- **Email**: info@velora.com
- **DocumentaciÃ³n**: Este archivo + `docs/INFORME_SISTEMA_EVALUACION.md`
- **CÃ³digo fuente**: Repositorio Git

---

*Documento generado para Velora - Sistema de EvaluaciÃ³n de Candidatos v2.1.0*

