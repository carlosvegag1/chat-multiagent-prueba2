# üéõÔ∏è Gu√≠a de Hiperpar√°metros de LLM - Velora Auto Evaluator

## Resumen Ejecutivo

Este documento explica c√≥mo se configuran los hiperpar√°metros de los modelos de lenguaje (LLMs) en el sistema, por qu√© se usan valores espec√≠ficos para cada contexto, y c√≥mo garantizamos compatibilidad entre proveedores.

---

## üìä Qu√© son los Hiperpar√°metros de LLM

Los hiperpar√°metros controlan el comportamiento del modelo al generar texto:

| Par√°metro | Rango | Efecto |
|-----------|-------|--------|
| **temperature** | 0.0 - 2.0 | Control de aleatoriedad. Bajo = determinista, Alto = creativo |
| **top_p** | 0.0 - 1.0 | Nucleus sampling. Controla diversidad de vocabulario |
| **max_tokens** | 1 - ‚àû | L√≠mite de longitud de respuesta |

### Temperature: El Par√°metro M√°s Importante

```
temperature = 0.0  ‚Üí  Siempre elige la palabra m√°s probable
temperature = 0.5  ‚Üí  Equilibrio entre coherencia y variedad
temperature = 1.0  ‚Üí  Alta creatividad, puede ser impredecible
temperature = 2.0  ‚Üí  Muy aleatorio, posible incoherencia
```

---

## üéØ Configuraci√≥n por Contexto en Velora

### Visi√≥n General

```mermaid
graph LR
    subgraph "FASE 1 - PRECISI√ìN"
        A[Extracci√≥n<br>temp=0.0] --> B[Matching<br>temp=0.1]
    end
    
    subgraph "FASE 2 - CONVERSACI√ìN"
        C[Entrevista<br>temp=0.3] --> D[Evaluaci√≥n<br>temp=0.2]
    end
    
    subgraph "RAG - INTERACCI√ìN"
        E[Chatbot<br>temp=0.4]
    end
    
    style A fill:#e8f5e9
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#e3f2fd
```

### Tabla de Configuraci√≥n Completa

| Contexto | Temperature | top_p | Justificaci√≥n |
|----------|-------------|-------|---------------|
| **Extracci√≥n de Requisitos** | 0.0 | 0.95 | M√°xima consistencia en identificaci√≥n |
| **Matching CV-Requisitos** | 0.1 | 0.95 | Precisi√≥n en evaluaci√≥n objetiva |
| **Generaci√≥n de Preguntas** | 0.3 | 0.90 | Naturalidad sin perder foco |
| **Evaluaci√≥n de Respuestas** | 0.2 | 0.95 | Interpretaci√≥n contextual precisa |
| **Chatbot RAG** | 0.4 | 0.85 | Conversaci√≥n fluida y amigable |

---

## üîß Implementaci√≥n en C√≥digo

### Ubicaci√≥n de Configuraci√≥n

```
src/evaluator/llm/hyperparameters.py  ‚Üê Configuraci√≥n centralizada
```

### Uso en Componentes

```python
from src.evaluator.llm import HyperparametersConfig

# Obtener temperatura para un contexto
temp = HyperparametersConfig.get_temperature("phase1_extraction")  # 0.0

# Obtener configuraci√≥n completa
config = HyperparametersConfig.get_config("rag_chatbot")
print(config.temperature)  # 0.4
print(config.top_p)        # 0.85

# Ver todos los contextos disponibles
contexts = HyperparametersConfig.list_contexts()
# ['phase1_extraction', 'phase1_matching', 'phase2_interview', ...]
```

### Integraci√≥n con LLMFactory

```python
from src.evaluator.llm import LLMFactory, HyperparametersConfig

# Crear LLM con hiperpar√°metros espec√≠ficos para contexto
config = HyperparametersConfig.get_config("phase1_matching")

llm = LLMFactory.create_llm(
    provider="openai",
    model_name="gpt-4o",
    temperature=config.temperature,  # 0.1
)
```

---

## üîÑ Compatibilidad Cross-Provider

### Par√°metros Universales (Usamos Estos)

| Par√°metro | OpenAI | Google Gemini | Anthropic Claude |
|-----------|--------|---------------|------------------|
| temperature | ‚úÖ | ‚úÖ | ‚úÖ |
| top_p | ‚úÖ | ‚úÖ | ‚úÖ |
| max_tokens | ‚úÖ | ‚úÖ (max_output_tokens) | ‚úÖ |

### Par√°metros Espec√≠ficos (NO Usamos)

| Par√°metro | Proveedor | Por qu√© NO lo usamos |
|-----------|-----------|---------------------|
| frequency_penalty | OpenAI only | No portable |
| presence_penalty | OpenAI only | No portable |
| top_k | Var√≠a | Comportamiento inconsistente |
| stop_sequences | Var√≠a | Manejado por LangChain |

### C√≥digo que Garantiza Portabilidad

```python
# En LLMFactory.create_llm():
kwargs = {
    "model": model_name,
    "temperature": temperature,  # Universal
}
# Solo pasamos par√°metros que funcionan en TODOS los proveedores
```

---

## üìã Justificaci√≥n Detallada por Fase

### FASE 1: Extracci√≥n y Matching

**Objetivo:** Precisi√≥n y consistencia absoluta

**¬øPor qu√© temperature = 0.0-0.1?**

1. **Reproducibilidad:** La misma oferta debe generar los mismos requisitos
2. **Objetividad:** El matching no debe depender de "suerte"
3. **Auditabilidad:** Resultados verificables y explicables

**Ejemplo de impacto:**

```
Con temperature = 0.0:
  Requisito: "5 a√±os de experiencia en Python" ‚Üí SIEMPRE igual

Con temperature = 0.8:
  Requisito 1: "5 a√±os de experiencia en Python"
  Requisito 2: "Experiencia significativa en Python (5+ a√±os)"
  Requisito 3: "Media d√©cada trabajando con Python"
  ‚Üí INCONSISTENTE
```

### FASE 2: Entrevista Interactiva

**Objetivo:** Naturalidad sin perder coherencia

**¬øPor qu√© temperature = 0.2-0.3?**

1. **Variedad:** Las preguntas no deben sonar rob√≥ticas
2. **Adaptabilidad:** Peque√±as variaciones mejoran la experiencia
3. **Control:** No tan alto como para generar incoherencias

**Ejemplo:**

```
Con temperature = 0.0:
  "¬øPuede describir su experiencia con Python?"  ‚Üí Siempre igual, rob√≥tico

Con temperature = 0.3:
  "¬øPodr√≠a contarme sobre su experiencia con Python?"
  "¬øC√≥mo describir√≠a su trayectoria trabajando con Python?"
  ‚Üí Natural, variado, coherente
```

### RAG Chatbot

**Objetivo:** Conversaci√≥n fluida basada en datos

**¬øPor qu√© temperature = 0.4?**

1. **El contexto RAG proporciona los datos:** No necesitamos precisi√≥n extrema
2. **Respuestas amigables:** El usuario espera interacci√≥n natural
3. **S√≠ntesis creativa:** Combinar informaci√≥n de m√∫ltiples evaluaciones

**Ejemplo:**

```
Pregunta: "¬øC√≥mo me ha ido en general?"

Con temperature = 0.1:
  "Has tenido 3 evaluaciones. Promedio: 75%. 2 aprobadas."
  ‚Üí Correcto pero fr√≠o

Con temperature = 0.4:
  "¬°Vas muy bien! De tus 3 evaluaciones, aprobaste 2 con un 
   promedio de 75%. Tu punto fuerte es la experiencia t√©cnica."
  ‚Üí Informativo y amigable
```

---

## üõ†Ô∏è C√≥mo Ajustar Hiperpar√°metros

### Paso 1: Identificar el Contexto

```python
# Ver contextos disponibles
from src.evaluator.llm import HyperparametersConfig
print(HyperparametersConfig.list_contexts())
```

### Paso 2: Modificar en hyperparameters.py

```python
# Ubicaci√≥n: src/evaluator/llm/hyperparameters.py

# Antes:
PHASE1_MATCHING = LLMHyperparameters(
    temperature=0.1,
    top_p=0.95,
)

# Despu√©s (si quieres m√°s determinismo):
PHASE1_MATCHING = LLMHyperparameters(
    temperature=0.0,  # Cambio
    top_p=0.95,
)
```

### Paso 3: Sin Cambios en L√≥gica de Negocio

Los componentes leen la configuraci√≥n autom√°ticamente. No necesitas modificar:
- `analyzer.py`
- `interviewer.py`
- `evaluator.py`
- `chatbot.py`

---

## üìä M√©tricas de Rendimiento por Configuraci√≥n

| Configuraci√≥n | Consistencia | Creatividad | Caso de Uso |
|---------------|--------------|-------------|-------------|
| temp=0.0 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | Extracci√≥n de datos |
| temp=0.1 | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Matching y evaluaci√≥n |
| temp=0.3 | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Generaci√≥n de preguntas |
| temp=0.5 | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Res√∫menes creativos |
| temp=0.7+ | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Brainstorming (no usado) |

---

## ‚úÖ Verificaci√≥n de Configuraci√≥n

```python
# Script de verificaci√≥n
from src.evaluator.llm import HyperparametersConfig

configs = HyperparametersConfig.get_all_configs()
for context, params in configs.items():
    print(f"{context}: temp={params['temperature']}, top_p={params.get('top_p', 'N/A')}")
```

**Salida esperada:**
```
phase1_extraction: temp=0.0, top_p=0.95
phase1_matching: temp=0.1, top_p=0.95
phase2_interview: temp=0.3, top_p=0.9
phase2_evaluation: temp=0.2, top_p=0.95
rag_chatbot: temp=0.4, top_p=0.85
summary: temp=0.3, top_p=0.9
```

---

## üîí Garant√≠as del Sistema

1. ‚úÖ **Independencia de proveedor:** Mismo comportamiento con OpenAI, Gemini, Claude
2. ‚úÖ **Configuraci√≥n centralizada:** Un solo archivo para todos los ajustes
3. ‚úÖ **Sin dependencias ocultas:** No usamos par√°metros provider-specific
4. ‚úÖ **F√°cil ajuste:** Cambiar valores sin tocar l√≥gica de negocio
5. ‚úÖ **Documentado:** Justificaci√≥n clara para cada decisi√≥n

---

**√öltima actualizaci√≥n:** Diciembre 2024  
**Versi√≥n:** 2.2.0

